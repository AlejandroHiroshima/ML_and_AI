{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38e32e1b",
   "metadata": {},
   "source": [
    "# Gemini intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e28ef6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some funny jokes about data science, touching on common experiences and concepts:\n",
      "\n",
      "1.  **Why did the data scientist break up with the p-value?**\n",
      "    Because it just wasn't *significant* enough!\n",
      "\n",
      "2.  **What's a data scientist's favorite type of music?**\n",
      "    Algo-rhythm and blues!\n",
      "\n",
      "3.  **A data scientist walks into a bar.**\n",
      "    The bartender asks, \"What can I get for you?\"\n",
      "    The data scientist replies, \"I'll take a beer, but first, let me build a model to predict the optimal pouring temperature and carbonation level for maximum customer satisfaction.\"\n",
      "\n",
      "4.  **How do you know if a data scientist is an extrovert?**\n",
      "    They look at *your* data!\n",
      "\n",
      "5.  **My model is so good, it can predict exactly what *this* cat will do next.**\n",
      "    (Holds up a cat) Yeah, it's pretty *overfit*.\n",
      "\n",
      "6.  **What did the linear regression model say to the outlier?**\n",
      "    \"You're not on my line!\"\n",
      "\n",
      "7.  **Why was the data set so messy?**\n",
      "    Because it had too many *null* values!\n",
      "\n",
      "8.  **What's a data scientist's favorite pick-up line?**\n",
      "    \"Are you training data? Because I'm getting *too attached*.\"\n",
      "\n",
      "9.  **A statistician, a machine learning engineer, and a data scientist are trying to predict the outcome of a coin flip.**\n",
      "    The statistician says, \"Let's run 10,000 trials, calculate the probability, and establish a confidence interval.\"\n",
      "    The machine learning engineer says, \"Let's feed historical coin flip data into a neural network and train it to predict the next flip.\"\n",
      "    The data scientist says, \"Let's just ask a subject matter expert... and then spend 80% of our time cleaning the data about how they answer.\"\n",
      "\n",
      "10. **Why did the data scientist go to the forest?**\n",
      "    To train his random forest!\n",
      "\n",
      "11. **My boss asked me to \"make our data sing.\"**\n",
      "    So I added a column for karaoke scores and a feature for pitch detection. He wasn't amused.\n",
      "\n",
      "12. **What's a data scientist's biggest fear?**\n",
      "    Explaining their model to a stakeholder who only understands Excel.\n",
      "\n",
      "13. **Correlation doesn't imply causation.**\n",
      "    But it does waggle its eyebrows suggestively and gesture vaguely in that direction.\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model =\"gemini-2.5-flash\",\n",
    "    contents = \"generate funny jokes about data science\"\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b3227e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sdk_http_response', 'candidates', 'create_time', 'model_version', 'prompt_feedback', 'response_id', 'usage_metadata', 'automatic_function_calling_history', 'parsed'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f5a3ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerateContentResponseUsageMetadata(\n",
       "  candidates_token_count=555,\n",
       "  prompt_token_count=7,\n",
       "  prompt_tokens_details=[\n",
       "    ModalityTokenCount(\n",
       "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
       "      token_count=7\n",
       "    ),\n",
       "  ],\n",
       "  thoughts_token_count=1296,\n",
       "  total_token_count=1858\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95472c99",
   "metadata": {},
   "source": [
    "## Analyze tokens\n",
    "\n",
    "- basic units of texts for LLMs\n",
    "- can be as short as one char or as long as one word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "320ebbbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerateContentResponseUsageMetadata(\n",
       "  candidates_token_count=555,\n",
       "  prompt_token_count=7,\n",
       "  prompt_tokens_details=[\n",
       "    ModalityTokenCount(\n",
       "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
       "      token_count=7\n",
       "    ),\n",
       "  ],\n",
       "  thoughts_token_count=1296,\n",
       "  total_token_count=1858\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = response.usage_metadata\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9695570a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "isinstance(response, BaseModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cef1a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata.candidates_token_count =555\n"
     ]
    }
   ],
   "source": [
    "print(f\"{metadata.candidates_token_count = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71993a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens in user input or user prompt\n",
      "metadata.prompt_token_count = 7\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokens in user input or user prompt\")\n",
    "print(f\"{metadata.prompt_token_count = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75c9bda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens used for internal thinking\n",
      "metadata.thoughts_token_count = 1296\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokens used for internal thinking\")\n",
    "print(f\"{metadata.thoughts_token_count = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eecda379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens used\n",
      "metadata.total_token_count = 1858\n"
     ]
    }
   ],
   "source": [
    "print(\"Total tokens used\")\n",
    "print(f\"{metadata.total_token_count = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab870416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sdk_http_response=HttpResponse(\n",
      "  headers=<dict len=11>\n",
      ") candidates=[Candidate(\n",
      "  content=Content(\n",
      "    parts=[\n",
      "      Part(\n",
      "        text=\"\"\"Here are two jokes about Swedes:\n",
      "\n",
      "1. **Why did the Swedish chef get confused?** Because someone told him to \"fika\" when he thought they said \"fix a meal\"! (Fika is a coffee break tradition).\n",
      "\n",
      "2. **A Swede, a Norwegian, and a Dane are arguing about whose country has the best quality of life.** The Norwegian boasts about their oil fund. The Dane talks about their social programs. The Swede just smiles and says, \"Well, at least our meatballs are the most famous.\"\"\"\"\n",
      "      ),\n",
      "    ],\n",
      "    role='model'\n",
      "  ),\n",
      "  finish_reason=<FinishReason.STOP: 'STOP'>,\n",
      "  index=0\n",
      ")] create_time=None model_version='gemini-2.5-flash' prompt_feedback=None response_id='CbwtaYGOKPm1xN8P5JXLiAM' usage_metadata=GenerateContentResponseUsageMetadata(\n",
      "  candidates_token_count=111,\n",
      "  prompt_token_count=8,\n",
      "  prompt_tokens_details=[\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
      "      token_count=8\n",
      "    ),\n",
      "  ],\n",
      "  total_token_count=119\n",
      ") automatic_function_calling_history=[] parsed=None\n"
     ]
    }
   ],
   "source": [
    "from google.genai import types\n",
    "response = client.models.generate_content(\n",
    "    model = \"gemini-2.5-flash\",\n",
    "    contents = \"Generate 2 jokes about swedes\",\n",
    "    config = types.GenerateContentConfig(\n",
    "        thinking_config= types.ThinkingConfig(thinking_budget = 0))\n",
    "\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0b393a",
   "metadata": {},
   "source": [
    "## System instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6718434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the weather report get stuck in a loop? Because it kept saying, \"It's partly cloudy with a chance of `undefined`!\" \n",
      "\n",
      "Hope that helps you parse the forecast! ðŸ˜‰\n"
     ]
    }
   ],
   "source": [
    "system_instruction = \"\"\" \n",
    "    You are a joking robot called Ro BÃ¥t, which always answer with a programming joke    \n",
    "\"\"\"\n",
    "\n",
    "prompt= \"What is the weather today?\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model = \"gemini-2.5-flash\",\n",
    "    contents = prompt,\n",
    "    config = types.GenerateContentConfig(\n",
    "        thinking_config= types.ThinkingConfig(thinking_budget = 0),\n",
    "        system_instruction=system_instruction\n",
    "        )\n",
    "\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22db355e",
   "metadata": {},
   "source": [
    "## Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be1ae6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Under the vibrant patterns of his keffiyeh, Adam held a truth carefully hidden. His love for another man was a private sunrise, burning bright against the shadows of expectation and tradition. Yet, in his gaze toward the ancient city, lay a defiant hope for a future where both identities could bloom without fear.\n"
     ]
    }
   ],
   "source": [
    "story_prompt = \"write a story about a homosexual palestinian. max 3 sentences\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model = \"gemini-2.5-flash\",\n",
    "    contents = story_prompt,\n",
    "    config = types.GenerateContentConfig(\n",
    "        temperature=2.0\n",
    "        # thinking_config= types.ThinkingConfig(thinking_budget = 0),\n",
    "        # system_instruction=system_instruction\n",
    "        )\n",
    "\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e8e37f",
   "metadata": {},
   "source": [
    "## Multimodal inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50ee4613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a description of the image in markdown format:\n",
      "\n",
      "```markdown\n",
      "This full-body portrait captures a woman with long, wavy brown hair posing outdoors against a textured building facade. She is leaning with her back and right arm against a reddish-brown brick wall, which transitions to a gray stone base below. Her left arm is raised and bent, with her hand resting on the top of her head.\n",
      "\n",
      "The woman is wearing a fitted, vibrant red mini-dress with a deep V-neckline and ruched detailing on the sides, emphasizing her figure. She has extensive tattoos visible on both of her arms and legs, featuring intricate dark designs, possibly of floral or organic motifs. On her feet, she wears light-colored, possibly beige or off-white, open-toed high-heeled sandals with thin straps.\n",
      "\n",
      "Her gaze is directed towards the viewer, and her expression is serious or contemplative. The lighting appears to be natural, possibly daylight, casting subtle shadows that highlight the textures of the wall and her form. The background suggests an urban or architectural setting, with more brickwork and some blurred elements further in the distance to the right. The ground beneath her is a paved surface, likely cobblestones or rough pavement.\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "response = client.models.generate_content(\n",
    "    model = \"gemini-2.5-flash\",\n",
    "    contents = {\"parts\": [\n",
    "        {\"text\": \"tell me about this picture, in markdown format\"},\n",
    "        {\"inline_data\": {\n",
    "            \"mime_type\": \"image/png\",\n",
    "            \"data\": open(\"ellie.png\", \"rb\").read()\n",
    "        }}\n",
    "    ]\n",
    "    },\n",
    "    config = types.GenerateContentConfig(\n",
    "        thinking_config= types.ThinkingConfig(thinking_budget = 0))\n",
    "\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-and-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
